import torch
import numpy as np
import librosa
import os
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2FeatureExtractor
from model_utils import load_audio_file, transcribe, convert_to_ipa

class PhonemeExtractor:
    def __init__(self):
        """
        Kh·ªüi t·∫°o m√¥ h√¨nh wav2vec2 ƒë·ªÉ tr√≠ch xu·∫•t phi√™n √¢m
        """
        print("üîÑ Kh·ªüi t·∫°o b·ªô tr√≠ch xu·∫•t phi√™n √¢m tr·ª±c ti·∫øp...")
        
        # S·ª≠ d·ª•ng m√¥ h√¨nh ti·∫øng Anh ƒë√°ng tin c·∫≠y thay v√¨ m√¥ h√¨nh ƒëa ng√¥n ng·ªØ
        self.model_id = "facebook/wav2vec2-large-960h-lv60-self"
        
        try:
            # T·∫£i m√¥ h√¨nh
            self.processor = Wav2Vec2Processor.from_pretrained(self.model_id)
            self.model = Wav2Vec2ForCTC.from_pretrained(self.model_id)
            self.model.eval()
            self.ready = True
            print("‚úÖ B·ªô tr√≠ch xu·∫•t phi√™n √¢m ƒë√£ s·∫µn s√†ng")
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi t·∫£i m√¥ h√¨nh phi√™n √¢m: {str(e)}")
            self.ready = False
            
        # √Ånh x·∫° phi√™n √¢m
        self.phoneme_map = {
            # Nguy√™n √¢m c∆° b·∫£n
            "i": "i", "e": "e", "a": "a", "o": "o", "u": "u",
            # Ph·ª• √¢m ph·ªï bi·∫øn
            "p": "p", "b": "b", "t": "t", "d": "d", "k": "k", 
            "g": "g", "f": "f", "v": "v", "s": "s", "z": "z",
            "m": "m", "n": "n", "l": "l", "r": "…π", "w": "w", 
            # K√Ω hi·ªáu ƒë·∫∑c bi·ªát
            "th": "Œ∏", "dh": "√∞", "sh": " É", "zh": " í",
            " ": " "
        }
            
    def get_phonemes_from_audio(self, audio_path):
        """
        Tr√≠ch xu·∫•t phi√™n √¢m t·ª´ √¢m thanh
        """
        # S·ª≠ d·ª•ng gi√°n ti·∫øp qua transcribe n·∫øu m√¥ h√¨nh kh√¥ng kh·ªüi t·∫°o th√†nh c√¥ng
        if not hasattr(self, 'ready') or not self.ready:
            result = transcribe(audio_path, output_ipa=True)
            return {
                "raw_phonemes": result["raw"],
                "ipa": result["ipa"],
                "method": "indirect"
            }
        
        # Ph∆∞∆°ng ph√°p tr·ª±c ti·∫øp
        try:
            # T·∫£i v√† x·ª≠ l√Ω √¢m thanh
            audio, sr = load_audio_file(audio_path, target_sr=16000)
            
            # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
            with torch.no_grad():
                input_values = self.processor(audio, return_tensors="pt", sampling_rate=16000).input_values
                logits = self.model(input_values).logits
            
            # L·∫•y d·ª± ƒëo√°n
            predicted_ids = torch.argmax(logits, dim=-1)
            
            # Gi·∫£i m√£ th√†nh vƒÉn b·∫£n
            text = self.processor.batch_decode(predicted_ids)[0]
            
            # Chuy·ªÉn th√†nh IPA
            ipa = convert_to_ipa(text)
            
            return {
                "raw_phonemes": text,
                "ipa": ipa,
                "method": "direct"
            }
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi tr√≠ch xu·∫•t phi√™n √¢m tr·ª±c ti·∫øp: {str(e)}")
            # Fallback v·ªÅ ph∆∞∆°ng ph√°p gi√°n ti·∫øp
            result = transcribe(audio_path, output_ipa=True)
            return {
                "raw_phonemes": result["raw"],
                "ipa": result["ipa"],
                "method": "indirect (fallback)"
            }

    def compare_phonemes(self, reference_phonemes, user_phonemes):
        """
        So s√°nh phi√™n √¢m tham chi·∫øu v·ªõi phi√™n √¢m ng∆∞·ªùi d√πng
        """
        try:
            from Levenshtein import distance
            
            # Chu·∫©n h√≥a chu·ªói phi√™n √¢m
            ref = ''.join(c for c in reference_phonemes if c.strip())
            user = ''.join(c for c in user_phonemes if c.strip())
            
            # T√≠nh kho·∫£ng c√°ch Levenshtein
            max_len = max(len(ref), len(user))
            if max_len == 0:
                similarity = 100.0
            else:
                edit_distance = distance(ref, user)
                similarity = ((max_len - edit_distance) / max_len) * 100
            
            return {
                "similarity": round(similarity, 2),
                "score": round(similarity / 10, 2),
                "edit_distance": distance(ref, user)
            }
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi so s√°nh phi√™n √¢m: {str(e)}")
            return {
                "similarity": 0,
                "score": 0,
                "edit_distance": -1
            }

# T·∫°o instance to√†n c·ª•c
phoneme_extractor = PhonemeExtractor()

def extract_phonemes(audio_path):
    """
    H√†m wrapper ƒë·ªÉ tr√≠ch xu·∫•t phi√™n √¢m t·ª´ √¢m thanh
    """
    return phoneme_extractor.get_phonemes_from_audio(audio_path)